package de.tub.processor.graph;

import java.sql.Timestamp;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

import org.neo4j.graphdb.GraphDatabaseService;
import org.neo4j.graphdb.Node;
import org.neo4j.graphdb.Path;
import org.neo4j.graphdb.traversal.Traverser;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import de.tub.data.dao.DAOFactory;
import de.tub.data.dao.Neo4JFrameworkClusterDAO;
import de.tub.data.dao.Neo4JStaypointDAO;
import de.tub.graph.TraversalDescriptions;
import de.tub.graph.generator.PrettyClusterIdGenerator;
import de.tub.observer.Interests;
import de.tub.observer.Observer;
import de.tub.observer.Subject;
import de.tub.processor.IProcessor;
import de.tub.reader.file.IterativeFileReader;
import de.tub.reader.file.TextFileLineReader;
import de.tub.util.DBUtil;
import de.tub.util.StringUtil;

/**
 * This processor handles the output of a clustering run
 * of OPTICS-XI with <a href="http://elki.dbs.ifi.lmu.de">ELKI</a>.
 * Therefore, it processes the output line-wise and creates a hierarchical
 * graph structure in a Neo4J graph database. 
 * <p />
 * This processor handles the interest <code>HasFinished</code> of a 
 * <code>TextFileLineReader</code> and an <code>IterativeFileReader</code>. The former
 * informs this processor about the finishing of the reading of the current resource, i.e.,
 * the current cluster file. Thereupon, this processor is finished with its <code>finish</code> 
 * method and the current cluster is connected to the graph's reference node if the cluster
 * is at the top of the cluster hierarchy.
 * <p />
 * The <code>IterativeFileReader</code> informs this processor about the finishing of all 
 * cluster files, i.e., the cluster hierarchy should be built up. Upon this, pretty cluster
 * ids are generated.
 * 
 * @author Sebastian Oelke
 * 
 * @see de.tub.graph.generator.PrettyClusterIdGenerator PrettyClusterIdGenerator
 *
 */
public class SharedFrameworkProcessor implements IProcessor<String>, Observer {
	
	private static final Logger LOG = LoggerFactory.getLogger(SharedFrameworkProcessor.class);

	private static final String COMMENT_LINE = "#";
	private static final String CLUSTER_REG = "# Cluster: ";
	private static final String PARENTS_REG = "# Parents: ";
	private static final String PARENTS_DELIMITER = " ";
	private static final String CHILDREN_REG = "# Children: ";
	private static final String CHILDREN_DELIMITER = " ";
	private static final String DATA_REG = "(\\s{1}\\d{1,3}\\.\\d+)|('[\\w\\s\\-:]*')";
	
	private String clusterId;
	
	private Neo4JFrameworkClusterDAO cDao = (Neo4JFrameworkClusterDAO) DAOFactory.instance().getFrameworkClusterDAO();
	private Neo4JStaypointDAO sDao = (Neo4JStaypointDAO) DAOFactory.instance().getStaypointDAO();
	
	/**
	 * The cluster which is currently processed.
	 */
	private Node currentCluster;
	
	/**
	 * Defines if the current cluster has a parent.
	 */
	private boolean hasParent;
	
	public SharedFrameworkProcessor() {
		// ...and other instance variables
		initialize();
	}
	
	@Override
	public void newData(String data) {
		// Return if their is no data or the reference is null
		if (data == null || data.isEmpty()) return;
		
		// Process the given data
		processData(data);
	}

	@Override
	public void finish() {
		// If the current node has no parents connect it to the graph's reference node
		// because it is at the top of the hierarchy.
		if (!hasParent && currentCluster != null)
			cDao.addRootFrameworkCluster(currentCluster.getGraphDatabase().getReferenceNode(), currentCluster);
		
		// Reset instance variables
		initialize();
	}
	
	/**
	 * Resets instance variables.
	 */
	private void initialize() {
		currentCluster = null;
		hasParent = false;
	}
	
	/**
	 * Does a traversal through the generated graph and gives pretty
	 * identifiers to each cluster.
	 */
	private void generatePrettyClusterIds() {
		LOG.debug("Generate pretty ids for framework clusters.");
		// Start the traversal from the graph's reference node to each framework cluster node
		// and generate a pretty id for each cluster
		GraphDatabaseService graph = DBUtil.graph();
		Traverser traverser = TraversalDescriptions.FRAMEWORK_CLUSTER_TRAVERSAL.traverse(graph.getReferenceNode());
		PrettyClusterIdGenerator prettyIdGenerator = new PrettyClusterIdGenerator();
		
		for (Path p : traverser) {
			// Generate a pretty id for each path end node
			prettyIdGenerator.generate(p);
		}
	}
	
	/**
	 * Processes the given data. This method reads lines of a cluster
	 * file generated by ELKI, extracts the cluster structure with
	 * framework clusters and stay points.
	 * 
	 * @param data the data to process.
	 */
	private void processData(String data) {
		// Cluster ID found
		if (data.startsWith(CLUSTER_REG)) {
			clusterId = data.replaceFirst(CLUSTER_REG, "");
			LOG.debug("Found cluster {}.", clusterId);
			
			// Check if cluster with given id already exists
			currentCluster = cDao.findFrameworkClusterById(clusterId);
			// Cluster has not been created, yet
			if (currentCluster == null) 
				currentCluster = cDao.createFrameworkCluster(clusterId);
		}
		// Parents of cluster found
		else if (data.startsWith(PARENTS_REG)) {
			String parents = data.replaceFirst(PARENTS_REG, "");
			String[] parentsArray = parents.split(PARENTS_DELIMITER);
			LOG.debug("Found parents of cluster {}: {}", clusterId, parentsArray);
			
			hasParent = true;
		}
		// Children of cluster found
		else if (data.startsWith(CHILDREN_REG)) {
			String children = data.replaceFirst(CHILDREN_REG, "");
			String[] childrenArray = children.split(CHILDREN_DELIMITER);
			LOG.debug("Found children of cluster {}: {}", clusterId, childrenArray);
			
			// Create new child cluster nodes for all found children and connect it to the current cluster node
			for (int i = 0; i < childrenArray.length; i++) {
				// Check if child already exists
				Node childExists = cDao.findFrameworkClusterById(childrenArray[i]);
				// Child has not been created, yet
				if (childExists == null)
					childExists = cDao.createFrameworkCluster(childrenArray[i]);
				
				// Create connection between current cluster and its child
				cDao.addChildFrameworkCluster(currentCluster, childExists);
			}
		}
		// Real data points
		else if (!data.startsWith(COMMENT_LINE)) {
			 /**
			  * Each data line of the ELKI output should have the following format:
			  *
			  *	ID=<elki_point_id> <point_latitude> <point_longitude> '<point_id>' '<point_arrival_time>' '<point_leaving_time>' reachability=<point_reachability_value>[ predecessor=<point_predecesor_value>]
			  *
			  * Concrete example: ID=24346 8.3352576 98.5045304 '24346' '2009-03-22 05:11:18' '2009-03-22 05:57:59' reachability=808.5024539029628 predecessor=28126
			  *	
			  *	Each line has seven to eight data tokens. Only the tokens two to six are relevant here.
			  */
			
			// Prepare regular expression to filter relevant data fields
			Pattern p = Pattern.compile(DATA_REG);
			Matcher m = p.matcher(data);
			
			String currentExtractedData = "";
			// The latitude and longitude values have to be trimmed because they are extracted with a leading space
			m.find();
			double lat = 0.0;
			currentExtractedData = m.group().trim();
			try {
				lat = Double.valueOf(currentExtractedData);
			} catch (NumberFormatException e) {
				LOG.error("The current latitude value [{}] could not be parsed as a decimal number:\n{}", currentExtractedData, e);
			}
			
			m.find();
			double lon = 0.0;
			currentExtractedData = m.group().trim();
			try {
				lon = Double.valueOf(currentExtractedData);
			} catch (NumberFormatException e) {
				LOG.error("The current longitude value [{}] could not be parsed as a decimal number:\n{}", currentExtractedData, e);
			}
			
			// The other values are enclosed by single quotes so ELKI treats them as labels; we have to remove the single quotes
			m.find();
			currentExtractedData = StringUtil.trimSingleQuotes(m.group());
			int id = 0;
			try {
				id = Integer.valueOf(currentExtractedData);
			} catch (NumberFormatException e) {
				LOG.error("The current id value [{}] could not be parsed as an integer number:\n{}", currentExtractedData, e);
			}
			
			// Neo4j does not support time stamps as node properties, 
			// to be able to order stay points by time later on we 
			// have to get the time as a long value
			m.find();
			currentExtractedData = StringUtil.trimSingleQuotes(m.group());
			long arr = 0L;
			try {
				arr = Timestamp.valueOf(currentExtractedData).getTime();
			} catch (IllegalArgumentException e) {
				LOG.error("The current arrival time value [{}] could not be parsed as a time stamp:\n{}", currentExtractedData, e);
			}
			
			m.find();
			currentExtractedData = StringUtil.trimSingleQuotes(m.group());
			long leav = 0L;
			try {
				leav = Timestamp.valueOf(currentExtractedData).getTime();
			} catch (IllegalArgumentException e) {
				LOG.error("The current leaving time value [{}] could not be parsed as a time stamp:\n{}", currentExtractedData, e);
			}
			
			// Create stay point with extracted data
			Node sp = sDao.createStayPoint(id, lat, lon, arr, leav);
			// Add stay point to current cluster
			cDao.addStayPoint(currentCluster, sp);
		}
	}

	@Override
	public void update(Subject theSubject, Interests interest, Object arg) {
		if (theSubject instanceof TextFileLineReader) {
			// A TextFileLineReader notifies us about its finishing
			if (interest == Interests.HasFinished) {
				// The reading of a cluster file ended, finish this processor
				finish();
			}
		} else if (theSubject instanceof IterativeFileReader) {
			// A IterativeFileReader notifies us about its finishing
			if (interest == Interests.HasFinished) {
				// The reading of all cluster files ended, the graph is built up,
				// generate pretty cluster ids
				generatePrettyClusterIds();
			}
		}
	}

}
